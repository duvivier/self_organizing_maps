{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Organizing Maps (SOMs) Notebook\n",
    "## Training step - Step 2\n",
    "\n",
    "**Notebook by Maria J. Molina (NCAR) and Alice DuVivier (NCAR).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook reads in data subset for a particular region and variable, done in step 1. Then it loops through a series of SOM hyperparameters to train a number of SOMs and determine the best size and such to answer the science questions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed imports\n",
    "\n",
    "from minisom import MiniSom, asymptotic_decay\n",
    "import xarray as xr\n",
    "import cftime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "from datetime import timedelta\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set user-specified information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set: variable to test, the location of the already extracted training data\n",
    "var_in = 'aice_d'\n",
    "sector_short = 'Ross'\n",
    "data_path = '/glade/p/cgd/ppc/duvivier/cesm2_antarctic_polynya/SOM_analysis/training/'+sector_short+'_v5/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load and get correct training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file saved in earlier notebook (soms_antarctica-gettingdata.ipynb)\n",
    "subset = xr.open_dataset(data_path+'training_data_region_'+sector_short+'_'+var_in+'.nc')\n",
    "\n",
    "# assign to numpy array object\n",
    "subsetarray = subset['train_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232300, 189)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check the data dims/shape - should match the dims from the getting data notebook\n",
    "print(subsetarray.shape)\n",
    "# confirm there are no NaN values in array for training (should print False if no values)\n",
    "print(np.isnan(subsetarray).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: SOM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set SOM Hyperparameters we'll test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set possible grid sizes. These are paired values.\n",
    "som_grid_rows    = [3, 4, 5]    # (y-axis)\n",
    "som_grid_cols    = [3, 4, 5]    # (x-axis)\n",
    "\n",
    "# for each SOM grid, we will need to all possible combos with parameters below\n",
    "# spread of neighborhood function - sigma - is set below and depends on the som shape\n",
    "###sigma            = [1.0, 0.5, 0.25, 0.1]\n",
    "# initial learning rate (at the iteration t we have learning_rate(t) = learning_rate / (1 + t/T) where T is #num_iteration/2)\n",
    "learning_rate    = [0.005, 0.01, 0.04, 0.05, 0.5]\n",
    "# how many iterations to go through\n",
    "num_iteration    = [10000, 50000, 100000, 250000, 500000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the normalizing data function\n",
    "def normalize_data(data):\n",
    "    \"\"\"\n",
    "    Function for normalizing data prior to training using z-score\n",
    "    \"\"\"\n",
    "    return (data - np.nanmean(data)) / np.nanstd(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set other attributes required for som training\n",
    "input_length = subsetarray.shape[1]      # Total number of points to train on per timestep\n",
    "decay_function = asymptotic_decay        # Function that reduces learning_rate and sigma at each iteration\n",
    "neighborhood_function = 'gaussian'       # Function that weights the neighborhood of a position in the map\n",
    "topology = 'rectangular'                 # Topology of the map; Possible values: 'rectangular', 'hexagonal'\n",
    "activation_distance = 'euclidean'        # Distance used to activate the map; Possible values: 'euclidean', 'cosine', 'manhattan', 'chebyshev'\n",
    "random_seed = 1                          # Random seed to use for reproducibility. Using 1.\n",
    "random_order = True\n",
    "verbose = False #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing grid: 3x3\n",
      "Testing 1 of 90\n",
      "Testing 2 of 90\n",
      "Testing 3 of 90\n",
      "Testing 4 of 90\n",
      "Testing 5 of 90\n",
      "Testing 6 of 90\n",
      "Testing 7 of 90\n",
      "Testing 8 of 90\n",
      "Testing 9 of 90\n",
      "Testing 10 of 90\n",
      "Testing 11 of 90\n",
      "Testing 12 of 90\n",
      "Testing 13 of 90\n",
      "Testing 14 of 90\n",
      "Testing 15 of 90\n",
      "Testing 16 of 90\n",
      "Testing 17 of 90\n",
      "Testing 18 of 90\n",
      "Testing 19 of 90\n",
      "Testing 20 of 90\n",
      "Testing 21 of 90\n",
      "Testing 22 of 90\n",
      "Testing 23 of 90\n",
      "Testing 24 of 90\n",
      "Testing 25 of 90\n",
      "Testing 26 of 90\n",
      "Testing 27 of 90\n",
      "Testing 28 of 90\n",
      "Testing 29 of 90\n",
      "Testing 30 of 90\n",
      "Testing 31 of 90\n",
      "Testing 32 of 90\n",
      "Testing 33 of 90\n",
      "Testing 34 of 90\n",
      "Testing 35 of 90\n",
      "Testing 36 of 90\n",
      "Testing 37 of 90\n",
      "Testing 38 of 90\n",
      "Testing 39 of 90\n",
      "Testing 40 of 90\n",
      "Testing 41 of 90\n",
      "Testing 42 of 90\n",
      "Testing 43 of 90\n",
      "Testing 44 of 90\n",
      "Testing 45 of 90\n",
      "Testing 46 of 90\n",
      "Testing 47 of 90\n",
      "Testing 48 of 90\n",
      "Testing 49 of 90\n",
      "Testing 50 of 90\n",
      "Testing 51 of 90\n",
      "Testing 52 of 90\n",
      "Testing 53 of 90\n",
      "Testing 54 of 90\n",
      "Testing 55 of 90\n",
      "Testing 56 of 90\n",
      "Testing 57 of 90\n",
      "Testing 58 of 90\n",
      "Testing 59 of 90\n",
      "Testing 60 of 90\n",
      "Testing 61 of 90\n",
      "Testing 62 of 90\n",
      "Testing 63 of 90\n",
      "Testing 64 of 90\n",
      "Testing 65 of 90\n",
      "Testing 66 of 90\n",
      "Testing 67 of 90\n",
      "Testing 68 of 90\n",
      "Testing 69 of 90\n",
      "Testing 70 of 90\n",
      "Testing 71 of 90\n",
      "Testing 72 of 90\n",
      "Testing 73 of 90\n",
      "Testing 74 of 90\n",
      "Testing 75 of 90\n",
      "Testing 76 of 90\n",
      "Testing 77 of 90\n",
      "Testing 78 of 90\n",
      "Testing 79 of 90\n",
      "Testing 80 of 90\n",
      "Testing 81 of 90\n",
      "Testing 82 of 90\n",
      "Testing 83 of 90\n",
      "Testing 84 of 90\n",
      "Testing 85 of 90\n",
      "Testing 86 of 90\n",
      "Testing 87 of 90\n",
      "Testing 88 of 90\n",
      "Testing 89 of 90\n",
      "Testing 90 of 90\n",
      "Writing out CSV file with all qerror for som grid 3x3\n",
      "Testing grid: 4x4\n",
      "Testing 1 of 120\n",
      "Testing 2 of 120\n",
      "Testing 3 of 120\n",
      "Testing 4 of 120\n",
      "Testing 5 of 120\n",
      "Testing 6 of 120\n",
      "Testing 7 of 120\n",
      "Testing 8 of 120\n",
      "Testing 9 of 120\n",
      "Testing 10 of 120\n",
      "Testing 11 of 120\n",
      "Testing 12 of 120\n",
      "Testing 13 of 120\n",
      "Testing 14 of 120\n",
      "Testing 15 of 120\n",
      "Testing 16 of 120\n",
      "Testing 17 of 120\n",
      "Testing 18 of 120\n",
      "Testing 19 of 120\n",
      "Testing 20 of 120\n",
      "Testing 21 of 120\n",
      "Testing 22 of 120\n",
      "Testing 23 of 120\n",
      "Testing 24 of 120\n",
      "Testing 25 of 120\n",
      "Testing 26 of 120\n",
      "Testing 27 of 120\n",
      "Testing 28 of 120\n",
      "Testing 29 of 120\n",
      "Testing 30 of 120\n",
      "Testing 31 of 120\n",
      "Testing 32 of 120\n",
      "Testing 33 of 120\n",
      "Testing 34 of 120\n",
      "Testing 35 of 120\n",
      "Testing 36 of 120\n",
      "Testing 37 of 120\n",
      "Testing 38 of 120\n",
      "Testing 39 of 120\n",
      "Testing 40 of 120\n",
      "Testing 41 of 120\n",
      "Testing 42 of 120\n",
      "Testing 43 of 120\n",
      "Testing 44 of 120\n",
      "Testing 45 of 120\n",
      "Testing 46 of 120\n",
      "Testing 47 of 120\n",
      "Testing 48 of 120\n",
      "Testing 49 of 120\n",
      "Testing 50 of 120\n",
      "Testing 51 of 120\n",
      "Testing 52 of 120\n",
      "Testing 53 of 120\n",
      "Testing 54 of 120\n",
      "Testing 55 of 120\n",
      "Testing 56 of 120\n",
      "Testing 57 of 120\n",
      "Testing 58 of 120\n",
      "Testing 59 of 120\n",
      "Testing 60 of 120\n",
      "Testing 61 of 120\n",
      "Testing 62 of 120\n",
      "Testing 63 of 120\n",
      "Testing 64 of 120\n",
      "Testing 65 of 120\n",
      "Testing 66 of 120\n",
      "Testing 67 of 120\n",
      "Testing 68 of 120\n",
      "Testing 69 of 120\n",
      "Testing 70 of 120\n",
      "Testing 71 of 120\n",
      "Testing 72 of 120\n",
      "Testing 73 of 120\n",
      "Testing 74 of 120\n",
      "Testing 75 of 120\n",
      "Testing 76 of 120\n",
      "Testing 77 of 120\n",
      "Testing 78 of 120\n",
      "Testing 79 of 120\n",
      "Testing 80 of 120\n",
      "Testing 81 of 120\n",
      "Testing 82 of 120\n",
      "Testing 83 of 120\n",
      "Testing 84 of 120\n",
      "Testing 85 of 120\n",
      "Testing 86 of 120\n",
      "Testing 87 of 120\n",
      "Testing 88 of 120\n",
      "Testing 89 of 120\n",
      "Testing 90 of 120\n",
      "Testing 91 of 120\n",
      "Testing 92 of 120\n",
      "Testing 93 of 120\n",
      "Testing 94 of 120\n",
      "Testing 95 of 120\n",
      "Testing 96 of 120\n",
      "Testing 97 of 120\n",
      "Testing 98 of 120\n",
      "Testing 99 of 120\n",
      "Testing 100 of 120\n",
      "Testing 101 of 120\n",
      "Testing 102 of 120\n",
      "Testing 103 of 120\n",
      "Testing 104 of 120\n",
      "Testing 105 of 120\n",
      "Testing 106 of 120\n",
      "Testing 107 of 120\n",
      "Testing 108 of 120\n",
      "Testing 109 of 120\n",
      "Testing 110 of 120\n",
      "Testing 111 of 120\n",
      "Testing 112 of 120\n",
      "Testing 113 of 120\n",
      "Testing 114 of 120\n",
      "Testing 115 of 120\n",
      "Testing 116 of 120\n",
      "Testing 117 of 120\n",
      "Testing 118 of 120\n",
      "Testing 119 of 120\n",
      "Testing 120 of 120\n",
      "Writing out CSV file with all qerror for som grid 4x4\n",
      "Testing grid: 5x5\n",
      "Testing 1 of 150\n",
      "Testing 2 of 150\n",
      "Testing 3 of 150\n",
      "Testing 4 of 150\n",
      "Testing 5 of 150\n",
      "Testing 6 of 150\n",
      "Testing 7 of 150\n",
      "Testing 8 of 150\n",
      "Testing 9 of 150\n",
      "Testing 10 of 150\n",
      "Testing 11 of 150\n",
      "Testing 12 of 150\n",
      "Testing 13 of 150\n",
      "Testing 14 of 150\n",
      "Testing 15 of 150\n",
      "Testing 16 of 150\n",
      "Testing 17 of 150\n",
      "Testing 18 of 150\n",
      "Testing 19 of 150\n",
      "Testing 20 of 150\n",
      "Testing 21 of 150\n",
      "Testing 22 of 150\n",
      "Testing 23 of 150\n",
      "Testing 24 of 150\n",
      "Testing 25 of 150\n",
      "Testing 26 of 150\n",
      "Testing 27 of 150\n",
      "Testing 28 of 150\n",
      "Testing 29 of 150\n",
      "Testing 30 of 150\n",
      "Testing 31 of 150\n",
      "Testing 32 of 150\n",
      "Testing 33 of 150\n",
      "Testing 34 of 150\n",
      "Testing 35 of 150\n",
      "Testing 36 of 150\n",
      "Testing 37 of 150\n",
      "Testing 38 of 150\n",
      "Testing 39 of 150\n",
      "Testing 40 of 150\n",
      "Testing 41 of 150\n",
      "Testing 42 of 150\n",
      "Testing 43 of 150\n",
      "Testing 44 of 150\n",
      "Testing 45 of 150\n",
      "Testing 46 of 150\n",
      "Testing 47 of 150\n",
      "Testing 48 of 150\n",
      "Testing 49 of 150\n",
      "Testing 50 of 150\n",
      "Testing 51 of 150\n",
      "Testing 52 of 150\n",
      "Testing 53 of 150\n",
      "Testing 54 of 150\n",
      "Testing 55 of 150\n",
      "Testing 56 of 150\n",
      "Testing 57 of 150\n",
      "Testing 58 of 150\n",
      "Testing 59 of 150\n",
      "Testing 60 of 150\n",
      "Testing 61 of 150\n",
      "Testing 62 of 150\n",
      "Testing 63 of 150\n",
      "Testing 64 of 150\n",
      "Testing 65 of 150\n",
      "Testing 66 of 150\n",
      "Testing 67 of 150\n",
      "Testing 68 of 150\n",
      "Testing 69 of 150\n",
      "Testing 70 of 150\n",
      "Testing 71 of 150\n",
      "Testing 72 of 150\n",
      "Testing 73 of 150\n",
      "Testing 74 of 150\n",
      "Testing 75 of 150\n",
      "Testing 76 of 150\n",
      "Testing 77 of 150\n",
      "Testing 78 of 150\n",
      "Testing 79 of 150\n",
      "Testing 80 of 150\n",
      "Testing 81 of 150\n",
      "Testing 82 of 150\n",
      "Testing 83 of 150\n",
      "Testing 84 of 150\n",
      "Testing 85 of 150\n",
      "Testing 86 of 150\n",
      "Testing 87 of 150\n",
      "Testing 88 of 150\n",
      "Testing 89 of 150\n",
      "Testing 90 of 150\n",
      "Testing 91 of 150\n",
      "Testing 92 of 150\n",
      "Testing 93 of 150\n",
      "Testing 94 of 150\n",
      "Testing 95 of 150\n",
      "Testing 96 of 150\n",
      "Testing 97 of 150\n",
      "Testing 98 of 150\n",
      "Testing 99 of 150\n",
      "Testing 100 of 150\n",
      "Testing 101 of 150\n",
      "Testing 102 of 150\n",
      "Testing 103 of 150\n",
      "Testing 104 of 150\n",
      "Testing 105 of 150\n",
      "Testing 106 of 150\n",
      "Testing 107 of 150\n",
      "Testing 108 of 150\n",
      "Testing 109 of 150\n",
      "Testing 110 of 150\n",
      "Testing 111 of 150\n",
      "Testing 112 of 150\n",
      "Testing 113 of 150\n",
      "Testing 114 of 150\n",
      "Testing 115 of 150\n",
      "Testing 116 of 150\n",
      "Testing 117 of 150\n",
      "Testing 118 of 150\n",
      "Testing 119 of 150\n",
      "Testing 120 of 150\n",
      "Testing 121 of 150\n",
      "Testing 122 of 150\n",
      "Testing 123 of 150\n",
      "Testing 124 of 150\n",
      "Testing 125 of 150\n",
      "Testing 126 of 150\n",
      "Testing 127 of 150\n",
      "Testing 128 of 150\n",
      "Testing 129 of 150\n",
      "Testing 130 of 150\n",
      "Testing 131 of 150\n",
      "Testing 132 of 150\n",
      "Testing 133 of 150\n",
      "Testing 134 of 150\n",
      "Testing 135 of 150\n",
      "Testing 136 of 150\n",
      "Testing 137 of 150\n",
      "Testing 138 of 150\n",
      "Testing 139 of 150\n",
      "Testing 140 of 150\n",
      "Testing 141 of 150\n",
      "Testing 142 of 150\n",
      "Testing 143 of 150\n",
      "Testing 144 of 150\n",
      "Testing 145 of 150\n",
      "Testing 146 of 150\n",
      "Testing 147 of 150\n",
      "Testing 148 of 150\n",
      "Testing 149 of 150\n",
      "Testing 150 of 150\n",
      "Writing out CSV file with all qerror for som grid 5x5\n"
     ]
    }
   ],
   "source": [
    "# Want to loop through the different SOM grid sizes and train each separately and write out CSV file\n",
    "\n",
    "for num_grid, (som_row,som_col) in enumerate(zip(som_grid_rows,som_grid_cols)):\n",
    "    #print(num_grid)\n",
    "    print('Testing grid: '+str(som_row)+'x'+str(som_col))\n",
    "\n",
    "    # set csv filename based on \n",
    "    fout = 'test_soms_qerror_'+sector_short+'_'+var_in+'_'+str(som_row)+'x'+str(som_col)+'.csv'\n",
    "    # array to put quantization errors for this grid\n",
    "    quant_errors = []\n",
    "    # set sigma values based on this som shape\n",
    "    sigma = list(np.hstack([0.5,list(range(1,som_col,1))]))\n",
    "\n",
    "    # creating list of hyperparameters for each SOM grid\n",
    "    list_of_sigs = []\n",
    "    list_of_lrts = []\n",
    "    list_of_itrs = []\n",
    "    for sig, lr, n_iter in product(sigma, learning_rate, num_iteration):\n",
    "        list_of_sigs.append(sig)\n",
    "        list_of_lrts.append(lr)\n",
    "        list_of_itrs.append(n_iter)\n",
    "    \n",
    "    # create empty csv\n",
    "    our_csv = pd.DataFrame(np.zeros((len(list_of_sigs), 6), dtype=int), columns=[\"n_row\", \"n_col\", \"sigma\", \"lr\", \"n_iter\", \"q_error\"])\n",
    "\n",
    "    \n",
    "    # now loop through the training parameters for this specific grid\n",
    "    for num_exp, (sig, lr, n_iter) in enumerate(zip(list_of_sigs,list_of_lrts,list_of_itrs)):\n",
    "        # print out which experiment for this grid we are on\n",
    "        print('Testing '+str(num_exp+1)+' of '+str(len(list_of_sigs)))\n",
    "        # normalize the training data - maybe take out??\n",
    "        data = normalize_data(subsetarray)\n",
    "        # initialize the SOM    \n",
    "        som = MiniSom(som_row,som_col,input_length,sig,lr,decay_function,\n",
    "                      neighborhood_function,topology,activation_distance,random_seed) \n",
    "    \n",
    "        som.pca_weights_init(data)  # Initializes the weights to span the first two principal components\n",
    "                                    # could also try random init: som.random_weights_init(data)\n",
    "        # train the SOM!\n",
    "        som.train(data,n_iter,random_order,verbose)\n",
    "        # Add to the csv file\n",
    "        our_csv.iloc[num_exp] += [som_row, som_col, sig, lr, n_iter, som.quantization_error(data)]    \n",
    "    \n",
    "    # Write the csv file for this grid after testing all the combinations\n",
    "    print('Writing out CSV file with all qerror for som grid '+str(som_row)+'x'+str(som_col))\n",
    "    our_csv.to_csv(fout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-antarctica_som_env]",
   "language": "python",
   "name": "conda-env-miniconda3-antarctica_som_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
