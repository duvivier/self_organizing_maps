{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ace6c8-30b6-42f3-aec2-4ef54f286d2d",
   "metadata": {},
   "source": [
    "# Self-Organizing Maps (SOMs) Notebook\n",
    "## Load \"winning\" SOMs - Step 4\n",
    "\n",
    "**Notebook by Maria J. Molina (NCAR) and Alice DuVivier (NCAR).**\n",
    "\n",
    "**Still very much in progress**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b68b9d3-aa1e-4144-bd7e-44ad450d7746",
   "metadata": {},
   "source": [
    "This Notebook reads in the pickle files saved as possible \"winning\" SOMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6f95a-6036-4b9a-bca7-90b40b17c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from minisom import MiniSom, asymptotic_decay\n",
    "import xarray as xr\n",
    "import cftime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "from datetime import timedelta\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sammon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4933c53-68c8-402a-a582-947196e42840",
   "metadata": {},
   "source": [
    "### Set User-specified information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877d3d4-04be-4352-928a-27dc4987c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set: variable to test, the location of the already extracted training data\n",
    "var_in = 'aice_d'\n",
    "sector_short = 'Ross'\n",
    "data_path = '/glade/p/cgd/ppc/duvivier/cesm2_antarctic_polynya/SOM_analysis/training/'+sector_short+'_v5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae491f5-f4f5-4677-a021-8c93ed8b948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set possible grid sizes. These are paired values.\n",
    "som_grid_rows    = [3, 4, 5]    # (y-axis)\n",
    "som_grid_cols    = [3, 4, 5]    # (x-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e204396-fd17-418e-8b22-0fd6f9ae2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL CHANGING REQUIRED HERE\n",
    "n = 2\n",
    "# n = 0-2 (matches sizes set above)\n",
    "\n",
    "som_row = som_grid_rows[n]\n",
    "som_col = som_grid_cols[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15729faa-b9fd-435b-8364-4c2417793633",
   "metadata": {},
   "source": [
    "### Load CSV with winning combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5bb00-9700-48e8-aeed-494562a15b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the file with all the possible soms\n",
    "df = pd.read_csv(data_path+'test_soms_qerror_'+sector_short+'_'+var_in+'_'+str(som_row)+'x'+str(som_col)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ad8d8-47ee-4a48-be9f-9bcb38b2b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values by q_error\n",
    "sorted_df = df.sort_values(['q_error'])\n",
    "\n",
    "# find and save the lowest qerror for top # (10)\n",
    "top_n = sorted_df.head(10)\n",
    "bottom_n = sorted_df.tail(10)\n",
    "#print(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f3354-64dc-44c0-93ec-6e33d74b6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the qerrors and make array against which to plot\n",
    "qerr_all = sorted_df.q_error\n",
    "xarr_all = np.arange(1,len(qerr_all)+1,1)\n",
    "qerr_n = top_n.q_error\n",
    "xarr_n = np.arange(1,len(qerr_n)+1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19479fe0-c74c-4aff-9ea9-6020d1e3027e",
   "metadata": {},
   "source": [
    "### Load training data - Needed to interpret the pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf18bb-8176-40a4-b7e1-c364fda784a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    \"\"\"\n",
    "    Function for normalizing data prior to training using z-score\n",
    "    \"\"\"\n",
    "    return (data - np.nanmean(data)) / np.nanstd(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847b2d1-ac4e-496c-ab17-b97df8dab76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file saved in earlier notebook (soms_antarctica-gettingdata.ipynb)\n",
    "subset = xr.open_dataset(data_path+'training_data_region_'+sector_short+'_'+var_in+'.nc')\n",
    "\n",
    "# assign to numpy array object\n",
    "subsetarray = subset['train_data'].values\n",
    "\n",
    "# set data\n",
    "data = normalize_data(subsetarray)\n",
    "\n",
    "# set data input length\n",
    "input_length = subsetarray.shape[1]    # using preprocessed data array; Number of the elements of the vectors in input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48896f9a-3812-4322-b7fb-24c0ab5badf5",
   "metadata": {},
   "source": [
    "## Plot frequencies across lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee132a-c821-4cb8-9cc5-1e3ffc6455c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the lowest values and load in the relevant pickle\n",
    "\n",
    "#for n in xarr_n[0:1]:\n",
    "for n in xarr_n:\n",
    "    print(str(n)+'th lowest qerror')\n",
    "    \n",
    "    # set the training values\n",
    "    qerr = top_n.iloc[n-1]['q_error'].item()\n",
    "    sig = top_n.iloc[n-1]['sigma'].item()\n",
    "    lr = top_n.iloc[n-1]['lr'].item()\n",
    "    n_iter = int(top_n.iloc[n-1]['n_iter'].item())\n",
    "    \n",
    "    # construct the input name from this, set as output for figure names\n",
    "    fin = 'som_'+sector_short+'_'+var_in+'_'+str(som_row)+'x'+str(som_col)+'_rank_'+str(n)+'_sig'+str(sig)+'_lr'+str(lr)+'_iter'+str(n_iter)\n",
    "\n",
    "    # open pickle\n",
    "    with open(data_path+'/pickles/'+fin+'.p', 'rb') as infile:\n",
    "        som = pickle.load(infile)\n",
    "\n",
    "    # set frequencies\n",
    "    frequencies = 100.*((som.activation_response(data))/sum(sum(som.activation_response(data))))\n",
    "    #verify the total frequency is 100%\n",
    "    total = sum(sum(frequencies))\n",
    "\n",
    "    # Plot frequencies across SOM lattice\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = plt.subplot(111)\n",
    "    im = ax.imshow(frequencies, cmap='Blues')   \n",
    "    \n",
    "    # Loop over data dimensions and create text annotations in each cell\n",
    "    len_x, len_y = frequencies.shape\n",
    "    for i in range(len_x):\n",
    "        for j in range(len_y):\n",
    "            text = ax.text(j, i, str(round(frequencies[i, j],1))+'%', fontsize=15,\n",
    "                       ha=\"center\", va=\"center\", color=\"k\")\n",
    "\n",
    "    # Make cosmetic changes\n",
    "    cbar = plt.colorbar(im)\n",
    "    plt.title(r\"data frequency (2d histogram) across SOM lattice\" \"\\n\" r\"total frequency = \"+str(total)+\"%\", fontsize=12)\n",
    "    plt.xticks(np.arange(0,som_row, 1))\n",
    "    plt.yticks(np.arange(0,som_col, 1))\n",
    "    \n",
    "    # save figure\n",
    "    fout = data_path+'som_evaluation/'+fin+'_freq.png'\n",
    "    plt.savefig(fout, bbox_inches='tight', dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf1d8e-18f7-46b0-8488-ada98c644064",
   "metadata": {},
   "source": [
    "## Plot Sammon maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911d9f2-9203-4e20-9b75-634291d298ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the lowest values and load in the relevant pickle\n",
    "\n",
    "#for n in xarr_n[0:1]:\n",
    "for n in xarr_n:\n",
    "    print(str(n)+'th lowest qerror')\n",
    "    \n",
    "    # set the training values\n",
    "    qerr = top_n.iloc[n-1]['q_error'].item()\n",
    "    sig = top_n.iloc[n-1]['sigma'].item()\n",
    "    lr = top_n.iloc[n-1]['lr'].item()\n",
    "    n_iter = int(top_n.iloc[n-1]['n_iter'].item())\n",
    "    \n",
    "    # construct the input name from this, set as output for figure names\n",
    "    fin = 'som_'+sector_short+'_'+var_in+'_'+str(som_row)+'x'+str(som_col)+'_rank_'+str(n)+'_sig'+str(sig)+'_lr'+str(lr)+'_iter'+str(n_iter)\n",
    "\n",
    "    # open pickle\n",
    "    with open(data_path+'/pickles/'+fin+'.p', 'rb') as infile:\n",
    "        som = pickle.load(infile)\n",
    "\n",
    "    # Calculate sammon coordinates (y) for map and \"map stress\" (E)\n",
    "    [y,E] = sammon.sammon(som.get_weights().reshape(som_col*som_row, input_length),2,display=1)\n",
    "\n",
    "    # Plot Sammon map nodes\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.scatter(y[:,0], y[:,1], s=20, c='black', marker='o')\n",
    "\n",
    "    # Add lines between nodes\n",
    "    tmp = np.reshape(y,(som_col,som_row,2))\n",
    "    len_x, len_y, len_z = tmp.shape\n",
    "    \n",
    "    # add vertical lines\n",
    "    for i in range(len_x-1):\n",
    "        for j in range(len_y):\n",
    "            plt.plot(tmp[i:i+2,j,0],tmp[i:i+2,j,1],c='black')\n",
    "    \n",
    "    # add horizontal lines\n",
    "    for i in range(len_x):\n",
    "        for j in range(len_y-1):\n",
    "            plt.plot(tmp[i,j:j+2,0],tmp[i,j:j+2,1],c='black')  \n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(r\"sammon map\" \"\\n\" r\"map stress = \"+str(E), fontsize=12)\n",
    "    \n",
    "    # save figure\n",
    "    fout = data_path+'som_evaluation/'+fin+'_sammon.png'\n",
    "    plt.savefig(fout, bbox_inches='tight', dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41a54a-197e-4bc6-bc6f-beddb87b8285",
   "metadata": {},
   "source": [
    "## Plot composite maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aaa794-46cd-41f0-acf2-9084d7e1577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set region of interest - for plotting\n",
    "titles     = ['Ross Sea', 'Amundsen Bellingshausen Sea', 'Weddell Sea', 'Pacific Ocean', 'Indian Ocean']\n",
    "shorts     = ['Ross', 'AMB', 'Wed', 'Pac', 'Ind']\n",
    "masks      = ['Ross_mask', 'BAm_mask', 'Wed_mask', 'Pac_mask', 'Ind_mask']\n",
    "lat_maxes  = [-72, -65, -65, -60, -60] \n",
    "lat_mins   = [-85, -85, -85, -80, -80]\n",
    "lon_maxes  = [200, 300, 300, 90, 160] \n",
    "lon_mins   = [160, 220, 20, 20, 90]\n",
    "lon_avgs   = [190, 260, 340, 55, 125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd2485-9f8f-49cb-ac10-a24dccb00517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on sector set at top of script, set plotting limits\n",
    "ind = shorts.index(sector_short)\n",
    "sector_title = titles[ind]\n",
    "mask_in = masks[ind]\n",
    "lat_max = lat_maxes[ind]\n",
    "lat_min = lat_mins[ind]\n",
    "lon_max = lon_maxes[ind]\n",
    "lon_min = lon_mins[ind]\n",
    "lon_avg = lon_avgs[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304aa56b-6bd5-4565-b5a4-350e9ca231a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for larger area than only training area\n",
    "# this data has been processed all the same 'time' coordinates as training data\n",
    "\n",
    "# set data path\n",
    "dir_in = data_path\n",
    "# file name for training variable only here \n",
    "fin = 'antarctic_data_for_som_composites_'+var_in\n",
    "# load data\n",
    "ds = xr.open_mfdataset(dir_in+fin+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d1ae8-ee26-4d62-9fef-6645b047130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly load data so that it doesn't take forever later on during mean\n",
    "ds = ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5932aae-477d-4e8c-8e8f-acc869244709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dictionary using the rows and columns of SOM\n",
    "keys = [i for i in product(range(som_row),range(som_col))]\n",
    "winmap = {key: [] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816a79c-cc8d-40cd-8f1f-46d9020154d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask  # importing dask just to skip warning message later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7273bf99-ebdf-4757-9221-f137cd37f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in xarr_n[5:]:\n",
    "#for n in xarr_n:\n",
    "    print(str(n)+'th lowest qerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e973c8-18cd-4903-a573-e0f640b7cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the som and get indices to put in the winmap\n",
    "\n",
    "# set some general plotting info\n",
    "cmap_choice = plt.cm.get_cmap('bone')  #'coolwarm'\n",
    "cmap_choice.set_bad(color='white')\n",
    "# set colorbar ticks to be equal to scale of vmin and vmax\n",
    "vmin_in = 0\n",
    "vmax_in = 1\n",
    "ticks_1 = np.arange(vmin_in,vmax_in,0.1)\n",
    "    \n",
    "for n in xarr_n:\n",
    "    print(str(n)+'th lowest qerror')\n",
    "    \n",
    "    # set the training values\n",
    "    qerr = top_n.iloc[n-1]['q_error'].item()\n",
    "    sig = top_n.iloc[n-1]['sigma'].item()\n",
    "    lr = top_n.iloc[n-1]['lr'].item()\n",
    "    n_iter = int(top_n.iloc[n-1]['n_iter'].item())\n",
    "    \n",
    "    # construct the input name from this, set as output for figure names\n",
    "    fin = 'som_'+sector_short+'_'+var_in+'_'+str(som_row)+'x'+str(som_col)+'_rank_'+str(n)+'_sig'+str(sig)+'_lr'+str(lr)+'_iter'+str(n_iter)\n",
    "\n",
    "    # open pickle\n",
    "    with open(data_path+'/pickles/'+fin+'.p', 'rb') as infile:\n",
    "        som = pickle.load(infile)\n",
    "\n",
    "    # set frequencies\n",
    "    frequencies = 100.*((som.activation_response(data))/sum(sum(som.activation_response(data))))\n",
    "    #verify the total frequency is 100%\n",
    "    total = sum(sum(frequencies))\n",
    "\n",
    "    # grab the indices for the data within the SOM lattice\n",
    "    for i, x in enumerate(data):\n",
    "        winmap[som.winner(x)].append(i) \n",
    "\n",
    "    # create list of the dictionary keys\n",
    "    som_keys = list(winmap.keys())\n",
    "    print(f\"Number of composite maps: {len(som_keys)}\")\n",
    "    print(f\"The rows and columns of the SOM lattice to use to grab SOM indexes:\\n{[i for i in list(winmap.keys())]}\")\n",
    "    \n",
    "    # set some of the plot info\n",
    "    fig, axs = plt.subplots(som_row, som_col, subplot_kw={'projection':ccrs.Stereographic(central_longitude=lon_avg)}, figsize=(14,12))\n",
    "    \n",
    "    # loop through the different maps to get the indices of training data that map there\n",
    "    for map_num in range(len(som_keys)):\n",
    "        # get indices of training data that mapped to this node\n",
    "        inds = winmap[som_keys[map_num]]\n",
    "        print(len(inds))\n",
    "        # grab the compositing data that corresponds to those training times\n",
    "        with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "            ds_sub = ds.isel(training_times=inds)          \n",
    "        ds_sub = ds_sub.mean(dim=\"training_times\", skipna=True)\n",
    "        \n",
    "        # make plot for this node - note using .values converts from xarray to numpy array\n",
    "        cs = axs[som_keys[map_num][0],som_keys[map_num][1]].pcolor(ds.coords['TLON'].values, \n",
    "                                                               ds.coords['TLAT'].values, \n",
    "                                                               ds_sub[\"data\"].values, \n",
    "                                                               vmin=0, vmax=1, cmap=cmap_choice,\n",
    "                                                               transform=ccrs.PlateCarree())\n",
    "        \n",
    "        axs[som_keys[map_num][0],som_keys[map_num][1]].set_extent([lon_min,lon_max,lat_min,lat_max])\n",
    "        axs[som_keys[map_num][0],som_keys[map_num][1]].coastlines(resolution='110m', color='0.25', linewidth=0.5, zorder=10)\n",
    "        axs[som_keys[map_num][0],som_keys[map_num][1]].add_feature(cartopy.feature.LAND, zorder=10, edgecolor='k', facecolor='w')    \n",
    "        axs[som_keys[map_num][0],som_keys[map_num][1]].gridlines(linestyle='--', linewidth=0.5, zorder=11)\n",
    "    \n",
    "        # plot titles\n",
    "        axs[som_keys[map_num][0],som_keys[map_num][1]].set_title('Node Frequency (%):{:.2f}'.format(frequencies.flatten()[map_num]), fontsize=12)\n",
    "    \n",
    "    # finalize figure \n",
    "    plt.suptitle(sector_title+' SOM '+var_in+' node composites - querror='+str(qerr), fontsize=12, x=0.515, y=0.925)\n",
    "\n",
    "    # colorbar stuff\n",
    "    # set axis for the colorbar e.g. ([x,y,dx,dy])\n",
    "    cbar_ax = fig.add_axes([0.25,0.1,0.5,0.01]) \n",
    "    cbar = fig.colorbar(cs, cax=cbar_ax, ticks=ticks_1[:],\n",
    "                        orientation='horizontal', extend='both')\n",
    "    cbar.ax.set_xticklabels(list(ticks_1))\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    cbar.set_label('ice concentration (frac)', fontsize=12)\n",
    "    \n",
    "    # save figure\n",
    "    fout = data_path+'som_evaluation/'+fin+'_composite.png'\n",
    "    plt.savefig(fout, bbox_inches='tight', dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2a980-e7f7-4d04-8d59-69c9fe36beb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-antarctica_som_env]",
   "language": "python",
   "name": "conda-env-miniconda3-antarctica_som_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
