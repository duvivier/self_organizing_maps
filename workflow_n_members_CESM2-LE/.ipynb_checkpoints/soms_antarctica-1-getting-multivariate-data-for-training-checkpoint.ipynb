{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Organizing Maps (SOMs) Notebook\n",
    "## Multivariate Data extraction step - Step 1\n",
    "\n",
    "**Notebook by Maria J. Molina (NCAR) and Alice DuVivier (NCAR).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook reads in data subset for a particular region and variable, done in step 1. Then it loops through a series of SOM hyperparameters to train a number of SOMs and determine the best size and such to answer the science questions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed imports\n",
    "\n",
    "from minisom import MiniSom, asymptotic_decay\n",
    "import xarray as xr\n",
    "import cftime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "from datetime import timedelta\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set user-specified information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set: variable to test, the location of the already extracted training data\n",
    "var_in_1 = 'aice_d'\n",
    "var_in_2 = 'hi_d'\n",
    "#set output name as the combo of the two\n",
    "var_in = var_in_1+'_'+var_in_2\n",
    "# set other info for training\n",
    "sector_short = 'Ross'\n",
    "data_path = '/glade/p/cgd/ppc/duvivier/cesm2_antarctic_polynya/SOM_analysis/training/'+sector_short+'_v5/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load and get correct training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file saved in earlier notebook (soms_antarctica-gettingdata.ipynb)\n",
    "subset_1 = xr.open_dataset(data_path+'training_data_region_'+sector_short+'_'+var_in_1+'.nc')\n",
    "subset_2 = xr.open_dataset(data_path+'training_data_region_'+sector_short+'_'+var_in_2+'.nc')\n",
    "\n",
    "# assign to numpy array object\n",
    "subsetarray_1 = subset_1['train_data'].values\n",
    "subsetarray_2 = subset_2['train_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data dims/shape - should match the dims from the getting data notebook\n",
    "# confirm there are no NaN values in array for training (should print False if no values)\n",
    "print(var_in_1)\n",
    "print(subsetarray_1.shape)\n",
    "print(np.isnan(subsetarray_1).any())\n",
    "\n",
    "print(var_in_2)\n",
    "print(subsetarray_2.shape)\n",
    "print(np.isnan(subsetarray_2).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into a single array that will have both variables\n",
    "# dims = ntraining x (2*npts)\n",
    "subsetarray = np.zeros([len(subset_1.training_times),2*len(subset_1.points)])\n",
    "\n",
    "# fill in the values from the two training datasets\n",
    "subsetarray[:,0:(len(subset_1.points))] = subsetarray_1[:,:]\n",
    "subsetarray[:,(len(subset_1.points)):(2*len(subset_1.points))] = subsetarray_2[:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data dims/shape - should match the dims from the getting data notebook\n",
    "# confirm there are no NaN values in array for training (should print False if no values)\n",
    "print(var_in)\n",
    "print(subsetarray.shape)\n",
    "print(np.isnan(subsetarray).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data as a netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = 'training_data_region_'+sector_short+'_'+var_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_save = xr.Dataset({'train_data': (['training_times','points'], subsetarray)}, \n",
    "                        coords={'time':(['training_times'],subset_1.time.values),\n",
    "                                'member_id':(['training_times'],subset_1.member_id.values)},\n",
    "                        attrs={'Author': 'Alice DuVivier'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_save.to_netcdf(fout+'.nc')  # how to save file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-antarctica_som_env]",
   "language": "python",
   "name": "conda-env-miniconda3-antarctica_som_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
